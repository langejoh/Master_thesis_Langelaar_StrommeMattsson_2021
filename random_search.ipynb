{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "furnished-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wired-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    ''' Constructs a Generalized Matrix Factorization model '''\n",
    "\n",
    "    def __init__(self, num_users=6040, num_items=3952, embeddings=64):\n",
    "        torch.manual_seed(0)\n",
    "        super().__init__()\n",
    "\n",
    "        # user and item embedding layers\n",
    "        self.user_embedding = nn.Embedding(num_users, embeddings).cuda()\n",
    "        self.item_embedding = nn.Embedding(num_items, embeddings).cuda()\n",
    "\n",
    "\n",
    "    def forward(self, user, item):\n",
    "\n",
    "        # map to embeddings\n",
    "        embedding1 = self.user_embedding(user).squeeze(1)\n",
    "        embedding2 = self.item_embedding(item).squeeze(1)\n",
    "\n",
    "        # Elementwise multiplication\n",
    "        GMF_layer = embedding1*embedding2\n",
    "        \n",
    "        # sum GMF layer\n",
    "        out = torch.sum(GMF_layer, 1).unsqueeze_(1)\n",
    "\n",
    "        # output between 0 and 1\n",
    "        out = torch.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    ''' Constructs a Multi-Layer Perceptron model'''\n",
    "\n",
    "    def __init__(self, num_users=6040, num_items=3952, embeddings=64, dropout=0):\n",
    "        torch.manual_seed(0)\n",
    "        super().__init__()\n",
    "\n",
    "        # user and item embedding layers\n",
    "        self.user_embedding = nn.Embedding(num_users, embeddings).cuda()\n",
    "        self.item_embedding = nn.Embedding(num_items, embeddings).cuda()\n",
    "\n",
    "        # MLP layers\n",
    "        self.l1 = nn.Linear(embeddings*2, embeddings).cuda()\n",
    "        self.l2 = nn.Linear(embeddings, int(embeddings/2)).cuda()\n",
    "        self.l3 = nn.Linear(int(embeddings/2), int(embeddings/4)).cuda()\n",
    "        self.l4 = nn.Linear(int(embeddings/4), 1, bias=False).cuda()\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = dropout\n",
    "        if self.dropout > 0:\n",
    "            self.drop = nn.Dropout(p=self.dropout)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "\n",
    "        # map to embeddings\n",
    "        embedding1 = self.user_embedding(user).squeeze(1)\n",
    "        embedding2 = self.item_embedding(item).squeeze(1)\n",
    "\n",
    "        # Concatenation of the embedding layers\n",
    "        out = torch.cat((embedding1, embedding2),1)\n",
    "\n",
    "        # feed through the MLP layers\n",
    "        out = F.relu(self.l1(out))\n",
    "        if self.dropout > 0:\n",
    "            out = self.drop(out)\n",
    "        \n",
    "        out = F.relu(self.l2(out))\n",
    "        if self.dropout > 0:\n",
    "            out = self.drop(out)\n",
    "            \n",
    "        out = F.relu(self.l3(out))\n",
    "        if self.dropout > 0:\n",
    "            out = self.drop(out)\n",
    "            \n",
    "        # output between 0 and 1\n",
    "        out = torch.sigmoid(self.l4(out))\n",
    "        return out\n",
    "\n",
    "class NeuMF(nn.Module):\n",
    "    ''' Constructs a Neural Matrix Factorization model '''\n",
    "\n",
    "    def __init__(self, num_users=6040, num_items=3952, embeddings=64, dropout=0):\n",
    "        torch.manual_seed(0)\n",
    "        super().__init__()\n",
    "\n",
    "        # GMF layers\n",
    "        self.GMF_user_embedding = nn.Embedding(num_users, embeddings).cuda()\n",
    "        self.GMF_item_embedding = nn.Embedding(num_items, embeddings).cuda()\n",
    "\n",
    "        # MLP layers\n",
    "        self.MLP_user_embedding = nn.Embedding(num_users, embeddings).cuda()\n",
    "        self.MLP_item_embedding = nn.Embedding(num_users, embeddings).cuda()\n",
    "        self.l1 = nn.Linear(embeddings*2, embeddings).cuda()\n",
    "        self.l2 = nn.Linear(embeddings, int(embeddings/2)).cuda()\n",
    "        self.l3 = nn.Linear(int(embeddings/2), int(embeddings/4)).cuda()\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = dropout\n",
    "        if self.dropout > 0:\n",
    "            self.drop = nn.Dropout(p=self.dropout)\n",
    "\n",
    "        # output layer\n",
    "        self.out = nn.Linear(int(embeddings/4 + embeddings), 1, bias=False).cuda()\n",
    "\n",
    "    def forward(self, user, item):\n",
    "\n",
    "        #GMF forward\n",
    "        GMF_latent1 = self.GMF_user_embedding(user).squeeze(1)\n",
    "        GMF_latent2 = self.GMF_item_embedding(item).squeeze(1)\n",
    "        GMF_layer = GMF_latent1*GMF_latent2\n",
    "\n",
    "        # MLP forward\n",
    "        MLP_latent1 = self.MLP_user_embedding(user).squeeze(1)\n",
    "        MLP_latent2 = self.MLP_item_embedding(item).squeeze(1)\n",
    "        MLP_layer = torch.cat((MLP_latent1, MLP_latent2),1) \n",
    "        MLP_layer = F.relu(self.l1(MLP_layer))\n",
    "        if self.dropout > 0:\n",
    "            MLP_layer = self.drop(MLP_layer)\n",
    "            \n",
    "        MLP_layer = F.relu(self.l2(MLP_layer))\n",
    "        if self.dropout > 0:\n",
    "            MLP_layer = self.drop(MLP_layer)\n",
    "        MLP_layer = F.relu(self.l3(MLP_layer))\n",
    "        if self.dropout > 0:\n",
    "            MLP_layer = self.drop(MLP_layer)\n",
    "\n",
    "        # Fusion\n",
    "        NeuMF_layer = torch.cat((GMF_layer, MLP_layer), 1)\n",
    "        out = torch.sigmoid(self.out(NeuMF_layer))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alpha-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingsData(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, num_negatives=4, validation=True, num_users=6040, num_items=3952, alfa=0.2):\n",
    "        np.random.seed(0)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.alfa = alfa\n",
    "        # Reads the data from file\n",
    "        r = pd.read_table(csv_file, sep=\"::\",\n",
    "                          names=[\"user_id\", \"movie_id\", \"rating\", \"timestamp\"], engine='python')\n",
    "        \n",
    "        self.length = len(r) # Number of interactions in the data set\n",
    "        self.ratings = self.load_as_matrix(r) # Interactions as a matrix structured as ((user,item) rating)\n",
    "        self.num_negatives = num_negatives # Number of negative instances per positive instance\n",
    "        # Lists of the users and items to train and test on\n",
    "        self.user_input, self.item_input, self.rating, self.test = self.get_train_instances(validation)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_input) # Length of the data to train on\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx): # idx is the index of the training instance\n",
    "        # User and item id as tensors\n",
    "        user = torch.LongTensor([self.user_input[idx] - 1]) # -1 so that indexing starts from 0\n",
    "        movie = torch.LongTensor([self.item_input[idx] - 1])\n",
    "        # Output label and loss weight as tensors\n",
    "        y = torch.ones(1)\n",
    "        w = torch.ones(1)\n",
    "        # Larger weight for higher ratings\n",
    "        w[0] = 1 + self.alfa * min(self.rating[idx], 1) * (self.rating[idx]-3)\n",
    "        y[0] = min(1, self.rating[idx])\n",
    "\n",
    "        return user, movie, y, w\n",
    "    \n",
    "    \n",
    "    def set_alfa(self, alfa):\n",
    "        self.alfa = alfa\n",
    "      \n",
    "\n",
    "    def load_as_matrix(self, ratings):\n",
    "        # Interactions as dictionary of keys (matrix)\n",
    "        mat = sp.dok_matrix((self.num_users + 1, self.num_items + 1), dtype=np.float32)\n",
    "\n",
    "        for i in range(self.length):\n",
    "            user, item, rating = int(ratings[\"user_id\"][i]), int(ratings[\"movie_id\"][i]), int(ratings[\"rating\"][i])\n",
    "            if (rating > 0):\n",
    "                #mat[user, item] = 1.0\n",
    "                mat[user, item] = rating\n",
    "\n",
    "        return mat\n",
    "\n",
    "\n",
    "    # if validation is True the last two interaction for each user will not be\n",
    "    # part of the training instances, and the penultimate will be used as test\n",
    "    # if False only the last interaction for each user will be left out and used as test\n",
    "    def get_train_instances(self, validation = True):\n",
    "        train = self.ratings\n",
    "        user_input, item_input, labels, test_item = [], [], [], []\n",
    "        last_u = 1\n",
    "        if validation:\n",
    "            skip = 2\n",
    "        else:\n",
    "            skip = 1\n",
    "\n",
    "        for (u, i) in train.keys():\n",
    "            if u > last_u: # Reaches the next user\n",
    "                # Remove the last instances\n",
    "                for k in range(skip*(self.num_negatives + 1)):\n",
    "                    user_input.pop()\n",
    "                    item = item_input.pop()\n",
    "                    labels.pop()\n",
    "                test_item.append(item) # save item for testing\n",
    "\n",
    "            # positive instance\n",
    "            user_input.append(u)\n",
    "            item_input.append(i)\n",
    "            labels.append(int(train[u, i]))\n",
    "\n",
    "            # Generate negative instances\n",
    "            for t in range(self.num_negatives): \n",
    "                j = np.random.randint(1, self.num_items+1)\n",
    "                # Keep generating items if the item has been interacted with\n",
    "                while (u, j) in train:\n",
    "                    j = np.random.randint(1, self.num_items+1)\n",
    "                user_input.append(u)\n",
    "                item_input.append(j)\n",
    "                labels.append(0)\n",
    "            last_u = u # Keep track on who the user was\n",
    "\n",
    "        # removing the last data points\n",
    "        for k in range(skip*(self.num_negatives + 1)):\n",
    "            user_input.pop()\n",
    "            item = item_input.pop()\n",
    "            labels.pop()\n",
    "        test_item.append(item) # save item for testing\n",
    "\n",
    "        return user_input, item_input, labels, test_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cheap-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_negatives(filename):\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        negatives = []\n",
    "        while line != None and line != \"\":\n",
    "            arr = line.split(\"\\t\")\n",
    "            for x in arr:\n",
    "                if x != \"\\n\":\n",
    "                    negatives.append(int(x))\n",
    "            line = f.readline()\n",
    "\n",
    "    return negatives\n",
    "\n",
    "\n",
    "def percentile(l, item):\n",
    "    index = 0\n",
    "    for element in l:\n",
    "        if element > item:\n",
    "            index+=1\n",
    "            return index\n",
    "        index+=1\n",
    "    return index\n",
    "\n",
    "\n",
    "def get_test_tensor(user, test_item, test_neg):\n",
    "  \n",
    "    test_item = test_item[user-1]\n",
    "\n",
    "    test_negatives = test_neg[100*(user-1):100*user]\n",
    "\n",
    "    user_tensor = torch.LongTensor([user-1])\n",
    "    user_test = torch.stack((user_tensor, user_tensor))\n",
    "    item_input = test_negatives[0]-1\n",
    "    item_input = torch.LongTensor([item_input])\n",
    "\n",
    "    user_tensor.unsqueeze_(0)\n",
    "\n",
    "    item_test = torch.LongTensor([test_item-1])\n",
    "    item_test = torch.stack((item_test, item_input))\n",
    "\n",
    "    for i in range(1,100):\n",
    "        item_input = test_negatives[i]-1\n",
    "        item_input = torch.LongTensor([item_input])\n",
    "        item_input.unsqueeze_(0)\n",
    "\n",
    "        user_test = torch.cat((user_test, user_tensor), 0)\n",
    "        item_test = torch.cat((item_test, item_input), 0)\n",
    "\n",
    "    return user_test, item_test\n",
    "\n",
    "\n",
    "def evaluate_model(model, validation=True, num_users=6040):\n",
    "    device = \"cuda\"\n",
    "    test_items = data.test\n",
    "    if validation:\n",
    "        test_neg = test_negatives(dir + \"validation_negatives.csv\")\n",
    "    else:\n",
    "        test_neg = test_negatives(dir + \"test_negatives.csv\")\n",
    "    hits = 0\n",
    "\n",
    "    for i in range(1, num_users+1):\n",
    "        user_test, item_test = get_test_tensor(i, test_items, test_neg)\n",
    "\n",
    "\n",
    "        user_test = user_test.to(device)\n",
    "        item_test = item_test.to(device)\n",
    "\n",
    "        l = model(user_test, item_test)\n",
    "        l = l.tolist()\n",
    "        l = sum(l,[])\n",
    "        first = l.pop(0)\n",
    "\n",
    "        l.sort()\n",
    "        percent = percentile(l, first)\n",
    "\n",
    "        if percent > 90:\n",
    "            hits+=1\n",
    "\n",
    "    hr = hits/6040\n",
    "    return hr\n",
    "\n",
    "\n",
    "def fit(model, data, batch_size, epochs, lr, verbose = True):\n",
    "    \n",
    "    device = \"cuda\"\n",
    "    print('Using device:', device)\n",
    "    # Defining optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    dataloader = DataLoader(data, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=0)\n",
    "\n",
    "    data_length = len(data)\n",
    "    it_per_epoch = len(data)/batch_size\n",
    "    tot_loss = 0\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    # Start training loop\n",
    "    for e in range(epochs):\n",
    "        print(\"Starting epoch \", e+1)\n",
    "        t1 = time.time()\n",
    "        i = 0\n",
    "        for batch in dataloader:\n",
    "            # Load tensors of users, movies, outputs and loss weights\n",
    "            u, m, y, w = batch \n",
    "            # move tensors to cuda\n",
    "            u = u.to(device)\n",
    "            m = m.to(device)\n",
    "            y = y.to(device)\n",
    "            w = w.to(device)\n",
    "\n",
    "            # make predictions\n",
    "            y_pred = model(u, m)\n",
    "\n",
    "            # Calculate mean loss\n",
    "            loss_fn = torch.nn.BCELoss(weight=w ,reduction = \"mean\")\n",
    "            #loss_fn = torch.nn.MSELoss(reduction = \"mean\")\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            tot_loss+=loss\n",
    "\n",
    "            # Backpropagate the output and updates model parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            i+=1\n",
    "\n",
    "            # Print progress\n",
    "            if i % int(1+it_per_epoch/10) == 0 and verbose:\n",
    "                #t2 = time.time()\n",
    "                print(\"Progress: \", int(100*i/it_per_epoch), \"%\")\n",
    "                #print(\"Time:\", int(t2-t1), \"seconds\")\n",
    "\n",
    "        # Epoch metrics\n",
    "        t2 = time.time()\n",
    "        print(\"Epoch time:\", int(t2-t1), \"seconds\")\n",
    "        print(\"Loss:\", tot_loss.item()/i)\n",
    "        print(\"Evaluating model...\")\n",
    "        print(\"Hit rate @10:\", evaluate_model(model, validation=True))\n",
    "        tot_loss = 0\n",
    "        print()\n",
    "\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "foreign-sugar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "dir = \"data/\"\n",
    "print(\"Processing data...\")\n",
    "data = RatingsData(dir + \"ratings.dat\", num_negatives=4, validation=True)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "unnecessary-colombia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ITERATIONS OF GRID SEARCH\n",
      "[0.1, 0.06309573444801933, 0.039810717055349734, 0.025118864315095794, 0.015848931924611134, 0.01, 0.00630957344480193, 0.003981071705534973, 0.0025118864315095794, 0.001584893192461114, 0.001]\n",
      "Starting search 1\n",
      "Using device: cuda\n",
      "Starting epoch  1\n",
      "Epoch time: 296 seconds\n",
      "Loss: 19.964172603626942\n",
      "Validating model...\n",
      "Hit rate @10: 0.669205298013245\n",
      "\n",
      "Done\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'validate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-89eb440208cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mhr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RESULT\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'validate_model' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "---\"Grid Search\"---\n",
    "Tune learning rate\n",
    "'''\n",
    "print(\"11 ITERATIONS OF GRID SEARCH\")\n",
    "\n",
    "lrates = [pow(10, -1), pow(10, -1.2), pow(10, -1.4), pow(10, -1.6),\n",
    "          pow(10, -1.8,), pow(10, -2), pow(10, -2.2), pow(10, -2.4), \n",
    "          pow(10, -2.6), pow(10, -2.8), pow(10, -3)]\n",
    "\n",
    "print(lrates)\n",
    "\n",
    "data.set_alfa(0)\n",
    "i = 1\n",
    "best_hr = 0\n",
    "best_lr = 0\n",
    "\n",
    "for lr in lrates:\n",
    "    print(\"Starting search\", i)\n",
    "    model = GMF()\n",
    "    # train\n",
    "    fit(model=model, data=data, batch_size=256, epochs=1, lr=lr, verbose=False)\n",
    "    hr = evaluate_model(model, validation=True)\n",
    "    \n",
    "    print(\"RESULT\")\n",
    "    print(\"HR@10:\", hr)\n",
    "    \n",
    "    if hr > best_hr:\n",
    "        best_hr = hr\n",
    "        best_lr = lr\n",
    "        \n",
    "    i+=1\n",
    "\n",
    "print(\"The best HR@10 was:\", best_hr)\n",
    "print(\"Using lr:\", best_lr)\n",
    "\n",
    "result_file = open(dir + \"hyper_MF.txt\", \"w+\")\n",
    "result_file.write(\"MF \\n\")\n",
    "result_file.write(\"lr \\t\" + str(best_lr) + \"\\n\")\n",
    "result_file.write(\"alfa \\t\" + str(best_alfa))\n",
    "result_file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "religious-memorabilia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 ITERATIONS OF RANDOM SEARCH\n",
      "\n",
      "\n",
      "Starting search 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-194fcc395c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting search\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Random value for learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_max\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlr_min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-081875eea96f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_users, num_items, embeddings)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# user and item embedding layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "'''--- Random search ---\n",
    "\n",
    "Hyperparameters to tune for NCF:\n",
    "\n",
    "1. learning rate (lr), logaritmically between 0.1 and 0.001\n",
    "2. weight parameter in loss function (alfa), linearly between 0 and 1\n",
    "\n",
    "Hyperparemters NOT to tune for NCF:\n",
    "1. number of negatives = 4\n",
    "2. embeddings = 16\n",
    "3. number of layers and weight initializations\n",
    "4. batch size = 256\n",
    "5. epochs = 8'''\n",
    "\n",
    "lr_min = 1\n",
    "lr_max = 3\n",
    "best_hr = 0\n",
    "best_lr = 0\n",
    "best_alfa = 0\n",
    "\n",
    "print(\"15 ITERATIONS OF RANDOM SEARCH\")\n",
    "print()\n",
    "\n",
    "for i in range(15):\n",
    "    print()\n",
    "    print(\"Starting search\", i+1)\n",
    "    model = GMF()\n",
    "    # Random value for learning rate\n",
    "    r1 = np.random.rand(1)[0]*(lr_max-1)+lr_min\n",
    "    lr = pow(10,-1*r1)\n",
    "    # Random value for alfa\n",
    "    alfa = np.random.rand(1)[0]\n",
    "    \n",
    "    # set value of alfa\n",
    "    data.set_alfa(alfa=alfa)\n",
    "    \n",
    "    # train\n",
    "    fit(model=model, data=data, batch_size=256, epochs=8, lr=lr, verbose=False)\n",
    "    hr = validate_model(model, validation=True)\n",
    "    print(\"RESULT\")\n",
    "    print(\"With lr=\", lr, \"and alfa=\", alfa)\n",
    "    print(\"HR@10:\", hr)\n",
    "\n",
    "    if hr > best_hr:\n",
    "        best_hr = hr\n",
    "        best_lr = lr\n",
    "        best_alfa = alfa\n",
    "\n",
    "        \n",
    "print(\"The best HR@10 was:\", best_hr)\n",
    "print(\"Using lr:\", best_lr)\n",
    "print(\"Using alfa:\", best_alfa)\n",
    "\n",
    "result_file = open(dir + \"hyper_GMF.txt\", \"w+\")\n",
    "result_file.write(\"GMF \\n\")\n",
    "result_file.write(\"lr \\t\" + str(best_lr) + \"\\n\")\n",
    "result_file.write(\"alfa \\t\" + str(best_alfa))\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-trauma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
